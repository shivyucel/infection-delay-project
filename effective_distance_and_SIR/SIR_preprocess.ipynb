{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4a495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from final_model import SIRModel\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc('figure', dpi=200)\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a84808d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/shivyucel/Documents/SDS_2021.nosync/SDS_2020-2021/SDS_Thesis/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55abad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(data_path + 'h3/paper_clean_commute.csv')\n",
    "df1 = df1[['SOURCE', 'TARGET', 'FLUX']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a50ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pivoted = df1.pivot(index=\"SOURCE\", columns=\"TARGET\", values=\"FLUX\").fillna(0)\n",
    "\n",
    "#pivoted = pivoted.loc[pivoted.index != 366]\n",
    "#pivoted.drop(366, axis=1, inplace=True)\n",
    "\n",
    "mxm_radiation = pivoted.values\n",
    "\n",
    "h3ids = pd.read_csv('/Users/shivyucel/Documents/SDS_2021.nosync/SDS_2020-2021/SDS_Thesis/Data/h3/h3_IDs.csv')\n",
    "\n",
    "h3ids.rename(columns={'Unnamed: 0': 'hex'}, inplace=True)\n",
    "\n",
    "\n",
    "relevant = pd.DataFrame(pivoted.index)\n",
    "\n",
    "relevant = relevant.merge(h3ids, left_on='SOURCE', right_on = '0')\n",
    "\n",
    "pop = pd.read_csv(data_path + 'h3/population/h3_pop.csv')\n",
    "\n",
    "merged = pop.merge(relevant, left_on='h3', right_on='hex')\n",
    "\n",
    "merged = merged.sort_values(by='0')\n",
    "\n",
    "\n",
    "populations = merged['2020_pop_h3'].values\n",
    "\n",
    "mobility_subpops = mxm_radiation.sum(axis=1)\n",
    "\n",
    "# Normalize the mobility matrix for each row (origin)\n",
    "mobility_normalized = (mxm_radiation.T / mobility_subpops).T \n",
    "\n",
    "population = (mobility_normalized.T * populations).T\n",
    "\n",
    "# Create the population-commuter table\n",
    "population = np.round(population).astype(int) \n",
    "\n",
    "print(population.sum(axis=1).min())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "91503e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2785, 2785)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b488e4db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "master_lst = []\n",
    "lst = []\n",
    "while population.sum(axis=1).min() <= 100:\n",
    "\n",
    "    if lst == []:\n",
    "        infile = data_path + 'h3/paper_clean_commute.csv'\n",
    "        df = pd.read_csv(infile)[['SOURCE', 'TARGET', 'FLUX']]\n",
    "        df1 = pd.DataFrame(df.groupby(['SOURCE', 'TARGET'])['FLUX'].agg(sum))\n",
    "        df1.reset_index(inplace=True)\n",
    "        pivoted = df1.pivot(index=\"SOURCE\", columns=\"TARGET\", values=\"FLUX\").fillna(0)\n",
    "    else:\n",
    "        pivoted.drop(index=lst, inplace=True)\n",
    "        pivoted.drop(labels=lst, axis=1, inplace=True)\n",
    "    \n",
    "    lst = []\n",
    "    mxm_radiation = pivoted.values\n",
    "    \n",
    "    h3ids = pd.read_csv(data_path + 'h3/commuting/h3_IDs.csv')\n",
    "    \n",
    "    h3ids.rename(columns={'Unnamed: 0': 'hex'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    relevant = pd.DataFrame(pivoted.index)\n",
    "    \n",
    "    relevant = relevant.merge(h3ids, left_on='SOURCE', right_on = '0')\n",
    "    \n",
    "    pop = pd.read_csv(data_path + 'h3/population/h3_pop.csv')\n",
    "    \n",
    "    merged = pop.merge(relevant, left_on='h3', right_on='hex')\n",
    "    \n",
    "    merged = merged.sort_values(by='0')\n",
    "    \n",
    "    populations = merged['2020_pop_h3'].values\n",
    "    \n",
    "    mobility_subpops = mxm_radiation.sum(axis=1)\n",
    "    \n",
    "    # Normalize the mobility matrix for each row (origin)\n",
    "    mobility_normalized = (mxm_radiation.T / mobility_subpops).T \n",
    "    \n",
    "    population = (mobility_normalized.T * populations).T\n",
    "    \n",
    "    # Create the population-commuter table\n",
    "    population = np.round(population).astype(int) \n",
    "    \n",
    "    df3 = pd.DataFrame(population, index=pivoted.index, columns=pivoted.columns)\n",
    "    \n",
    "    for ind, row in df3.iterrows():\n",
    "        if row.sum() <= 100:\n",
    "            lst.append(ind)\n",
    "            master_lst.append(ind)\n",
    "    \n",
    "    print(population.sum(axis=1).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2746d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv(data_path + 'h3/population/h3_pop.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea1a9089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "16\n",
      "23\n",
      "91\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "row_lst = []\n",
    "lst = []\n",
    "while population.sum(axis=0).min() <= 100:\n",
    "\n",
    "    if lst == []:\n",
    "        infile = data_path + 'h3/paper_clean_commute.csv'\n",
    "        df = pd.read_csv(infile)[['SOURCE', 'TARGET', 'FLUX']]\n",
    "        df1 = pd.DataFrame(df.groupby(['SOURCE', 'TARGET'])['FLUX'].agg(sum))\n",
    "        df1.reset_index(inplace=True)\n",
    "        pivoted = df1.pivot(index=\"SOURCE\", columns=\"TARGET\", values=\"FLUX\").fillna(0)\n",
    "    else:\n",
    "        pivoted.drop(index=lst, inplace=True)\n",
    "        pivoted.drop(labels=lst, axis=1, inplace=True)\n",
    "    \n",
    "    lst = []\n",
    "    mxm_radiation = pivoted.values\n",
    "    \n",
    "    h3ids = pd.read_csv(data_path + 'h3/commuting/h3_IDs.csv')\n",
    "    \n",
    "    h3ids.rename(columns={'Unnamed: 0': 'hex'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    relevant = pd.DataFrame(pivoted.index)\n",
    "    \n",
    "    relevant = relevant.merge(h3ids, left_on='SOURCE', right_on = '0')\n",
    "    \n",
    "    pop = pd.read_csv(data_path + 'h3/population/h3_pop.csv')\n",
    "    \n",
    "    merged = pop.merge(relevant, left_on='h3', right_on='hex')\n",
    "    \n",
    "    merged = merged.sort_values(by='0')\n",
    "    \n",
    "    populations = merged['2020_pop_h3'].values\n",
    "    \n",
    "    mobility_subpops = mxm_radiation.sum(axis=1)\n",
    "\n",
    "    # Normalize the mobility matrix for each row (origin)\n",
    "    mobility_normalized = (mxm_radiation.T / mobility_subpops).T \n",
    "    \n",
    "    population = (mobility_normalized.T * populations).T\n",
    "    \n",
    "    # Create the population-commuter table\n",
    "    population = np.round(population).astype(int) \n",
    "    \n",
    "    df3 = pd.DataFrame(population, index=pivoted.index, columns=pivoted.columns)\n",
    "    \n",
    "    for column in df3.columns:\n",
    "        if df3[column].sum() <= 100:\n",
    "            lst.append(column)\n",
    "            row_lst.append(column)\n",
    "    \n",
    "    print(population.sum(axis=0).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623791a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_lst = master_lst + row_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "260c5731",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1['SOURCE'].isin(full_lst)]\n",
    "df1 = df1[~df1['TARGET'].isin(full_lst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "652a62b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = df1.pivot(index=\"SOURCE\", columns=\"TARGET\", values=\"FLUX\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f88a30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6b4b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = h3_ids.merge(pop, left_on='Unnamed: 0', right_on='h3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b68b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_pop = merged[merged['0'].isin(pivoted.index)]['2020_pop_h3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd53ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(data_path + 'h3/mxm_updated_real.csv', pivoted.values,  delimiter =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09ff0a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(data_path + 'h3/population/new_h3_pop.txt', filtered_pop.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "264a4db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivoted.to_csv('correct_indices.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3000151dad639a5b884f482d55293518d422e78d7667ef7f9f66f3633cb45ad0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
